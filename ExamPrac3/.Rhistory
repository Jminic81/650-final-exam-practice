filter(yearID>=1970)%>%
group_by(playerID)%>%
summarize(maxHR=max(HR))%>%
filter(maxHR>50)%>%
select(playerID)
blogdown:::new_post_addin()
library(blogdown)
install_hugo()
new_site(theme=ageekymonk/hugo-tracks-theme"")
new_site(theme=ageekymonk/hugo-tracks-theme")
library(blogdown)
install_hugo()
new_site(theme="ageeklymonk/hugo-tracks-theme")
serve_site()
library(devtools)
library(blogdown)
build_site()
serve_site()
serve_site()
blogdown::serve_site()
install_github("r/studio/blogdown")
install.packages("devtools")
install_github("rstudio/blogdown")
library(blogdown)
install_hugo()
build_site()
serve_site()
library(devtools)
library(blogdown)
install_hugo()
install.packages("Lahman")
library("dplyr", lib.loc="~/R/win-library/3.4")
install.packages("ggplot2")
install.packages("ggiraph")
library(Lahman)
library(dplyr)
library(ggplot2)
library(ggiraph)
df<-Batting%>%
group_by(playerID)%>%
summarize(career_HR=sum(HR),career_SO=sum(SO))%>%
filter(career_HR>=400)
df
df<-Batting%>%
group_by(playerID)%>%
summarize(career_HR=sum(HR),career_SO=sum(SO))%>%
filter(career_HR>=400)
df<-Batting%>%
group_by(playerID)%>%
summarize(career_HR=sum(HR),career_SO=sum(SO))%>%
filter(career_HR>=400)
df
df<-Batting%>%
group_by(playerID)%>%
summarize(career_HR=sum(HR),career_SO=sum(SO))%>%
filter(career_HR>=400)
df
colnames(Master)
inner_join(df,Master,by=c("playerID"))%>%
select(nameFirst, nameLast,career_HR,career_SO)
ggplot()+
geom_point(data=HR_vs_SO,aes(x=career_SO,y=career_HR))
HR_vs_SO<-inner_join(df,Master,by=c("playerID"))%>%
select(nameFirst, nameLast,career_HR,career_SO)
ggplot()+
geom_point(data=HR_vs_SO,aes(x=career_SO,y=career_HR))
g<-ggplot()+
geom_point_interactive(data=HR_vs_SO,aes(x=career_SO,y=career_HR,tooltip=nameLast))+
ggtitle("Career Homeruns vs. Strikeouts for Great Hitters")+
xlab("Career Strikeouts")+
ylab("Career Homeruns")
ggiraph(code=print(g))
g<-ggplot()+
geom_point_interactive(data=HR_vs_SO,aes(x=career_SO,y=career_HR,tooltip=nameLast))+
ggtitle("Career Homeruns vs. Strikeouts for Great Hitters")+
xlab("Career Strikeouts")+
ylab("Career Homeruns")
ggiraph(code=print(g))
paste(HR_vs_SO$nameFirst,HR_vs_SO$nameLast)
HR_vs_SO$name<-paste(HR_vs_SO$nameFirst,HR_vs_SO$nameLast)
HR_vs_SO
g<-ggplot()+
geom_point_interactive(data=HR_vs_SO,aes(x=career_SO,y=career_HR,tooltip=name))+
ggtitle("Career Homeruns vs. Strikeouts for Great Hitters")+
xlab("Career Strikeouts")+
ylab("Career Homeruns")
ggiraph(code=print(g))
g<-ggplot()+
geom_point_interactive(data=HR_vs_SO,aes(x=career_SO,y=career_HR,tooltip=name,data_id=nameLast))+
ggtitle("Career Homeruns vs. Strikeouts for Great Hitters")+
xlab("Career Strikeouts")+
ylab("Career Homeruns")
ggiraph(code=print(g),hover_css="fill:white;stroke:black")
library("dplyr", lib.loc="~/R/win-library/3.4")
library("tidytext", lib.loc="~/R/win-library/3.4")
library("tm", lib.loc="~/R/win-library/3.4")
library("wordcloud", lib.loc="~/R/win-library/3.4")
install.packages("janeaustenr")
library("dplyr", lib.loc="~/R/win-library/3.4")
library("janeaustenr", lib.loc="~/R/win-library/3.4")
library("tidytext", lib.loc="~/R/win-library/3.4")
library("tm", lib.loc="~/R/win-library/3.4")
library("wordcloud", lib.loc="~/R/win-library/3.4")
austen_books()
class(sns)
sns<-austen_books()
sns<-austen_books()
head.sns
sns<-austen_books()
sns<-austen_books()
head(sns)
sns%>%
sns<-sns%>%
filter(book == 'Sense & Sensibility')
sns<-austen_books()
sns<-sns%>%
filter(book == 'Sense & Sensibility')
tail(sns)
tail(sns$book)
sns$book<-as.character(sns$book)
str(sns$book)
head(sns)
library("stringr", lib.loc="~/R/win-library/3.4")
str_detect(sns$text, '^CHAPTER')
str_detect(sns$text,'^CHAPTER')
sns$book<-as.character(sns$book)
str_detect(sns$text,'^CHAPTER')
str_detect(sns$text,'^CHAPTER')
sns<-austen_books()
sns<-sns%>%
filter(book == 'Sense & Sensibility')
sns$book<-as.character(sns$book)
str_detect(sns$text,'^CHAPTER')
sns%>%
filter(str_detect(sns$text,'^CHAPTER'))
str_detect(sns$text,'^CHAPTER')
library("stringr", lib.loc="~/R/win-library/3.4")
str_detect(sns$text,'^CHAPTER')
sns<-austen_books()
sns<-sns%>%
filter(book == 'Sense & Sensibility')
sns$book<-as.character(sns$book)
tr_detect(sns$text,'^CHAPTER')
library("stringr", lib.loc="~/R/win-library/3.4")
library("stringr", lib.loc="~/R/win-library/3.4")
library("stringr", lib.loc="~/R/win-library/3.4")
library(stringr)
.rs.restartR()
library(stringr)
library("dplyr", lib.loc="~/R/win-library/3.4")
sns%>%
filter(!str_detect(sns$text,'^CHAPTER'))
sns[12:12574,]
library("tidytext", lib.loc="~/R/win-library/3.4")
library("tm", lib.loc="~/R/win-library/3.4")
library("wordcloud", lib.loc="~/R/win-library/3.4")
library("janeaustenr", lib.loc="~/R/win-library/3.4")
sns<-austen_books()
sns<-sns%>%
filter(book == 'Sense & Sensibility')
sns$book<-as.character(sns$book)
str_detect(sns$text,'^CHAPTER')
sns%>%
filter(!str_detect(sns$text,'^CHAPTER'))
sns[12:12574,]
dim(sns)
sns<-sns[12:12574,]
sns<-sns[1:12562,]
sns%>%
unnest_tokens(word,text)
stop_words
words_df%>%
filter(!word %in% stop_words$word)
words_df<-sns%>%
unnest_tokens(word,text)
words_df%>%
filter(!word %in% stop_words$word)
words_df%>%words_df%>%
filter(!word %in% stop_words$word)
words_df<-sns%>%
unnest_tokens(word,text)
words_df%>%words_df%>%
filter(!word %in% stop_words$word)
words_df<-words_df%>%
filter(!word %in% stop_words$word)
words_df<-sns%>%
unnest_tokens(word,text)
words_df<-words_df%>%
filter(!word %in% stop_words$word)
words_df<-words_df%>%
filter(!(word %in% stop_words$word))
words_df
word_freq<-words_df%>%
group_by(word)%>%
summarize(count=n())
word_freq<-words_df%>%
group_by(word)%>%
summarize(count=n())
word_freq
wordcloud(word_freq$word,word_freq$count)
wordcloud(word_freq$word,word_freq$count,min.freq=100)
wordcloud(word_freq$word,word_freq$count,min.freq=25)
wordcloud(word_freq$word,word_freq$count)
wordcloud(word_freq$word,word_freq$count,min.freq=25)
wordcloud(word_freq$word,word_freq$count,min.freq=25)
setwd("C:/Users/Judy/Desktop/Austen2")
setwd("C:/Users/Judy/Desktop/Austenred/austen")
install.packages("bibtex")
install.packages(c("backports", "curl", "dplyr", "glue", "lazyeval", "lubridate", "officer", "purrr", "Rcpp", "rvg"))
install.packages(c("backports", "curl", "dplyr", "glue", "lazyeval", "lubridate", "officer", "purrr", "Rcpp", "rvg"))
install.packages(c("backports", "curl", "dplyr", "glue", "lazyeval", "lubridate", "officer", "purrr", "Rcpp", "rvg"))
install.packages(c("backports", "curl", "dplyr", "glue", "lazyeval", "lubridate", "officer", "purrr", "Rcpp", "rvg"))
install.packages(c("backports", "curl", "dplyr", "glue", "lazyeval", "lubridate", "officer", "purrr", "Rcpp", "rvg"))
install.packages(c("backports", "curl", "dplyr", "glue", "lazyeval", "lubridate", "officer", "purrr", "Rcpp", "rvg"))
install.packages(c("backports", "curl", "dplyr", "glue", "lazyeval", "lubridate", "officer", "purrr", "Rcpp", "rvg"))
install.packages(c("backports", "curl", "dplyr", "glue", "lazyeval", "lubridate", "officer", "purrr", "Rcpp", "rvg"))
install.packages(c("backports", "curl", "dplyr", "glue", "lazyeval", "lubridate", "officer", "purrr", "Rcpp", "rvg"))
install.packages(c("backports", "curl", "dplyr", "glue", "lazyeval", "lubridate", "officer", "purrr", "Rcpp", "rvg"))
install.packages(c("backports", "curl", "dplyr", "glue", "lazyeval", "lubridate", "officer", "purrr", "Rcpp", "rvg"))
install.packages(c("backports", "curl", "dplyr", "glue", "lazyeval", "lubridate", "officer", "purrr", "Rcpp", "rvg"))
library(knitr)
#find the id number of the work we are interested in.  Running this gets it
#to show up in the Consule = 345
gutenberg_works(title=='raven')
#We need the id number of a book that we don't know the whole title.  Use
#stringr to find a word in the title
gutenberg_works(title==str_detet(title,'Frankenstein'))
gutenberg_works(title==str_detet(author,'Poe'))
gutenberg_works(title=='Dracula')
library("gutenbergr", lib.loc="~/R/win-library/3.4")
gutenberg_works(title==str_detet(author,'Poe'))
library("stringr", lib.loc="~/R/win-library/3.4")
gutenberg_works(title==str_detet(author,'Poe'))
gutenberg_works(title=='Dracula')
library("dplyr", lib.loc="~/R/win-library/3.4")
#find the id number of the work we are interested in.  Running this gets it
#to show up in the Consule = 345
gutenberg_works(title=='Dracula')
#We need the id number of a book that we don't know the whole title.  Use
#stringr to find a word in the title
gutenberg_works(title==str_detet(title,'Frankenstein'))
gutenberg_works(title=='Dracula')
words_df<-sns%>%
unnest_tokens(word,text)
words_df<-words_df%>%
filter(!(word %in% stop_words$word))
word_freq<-words_df%>%
group_by(word)%>%
summarize(count=n())
wordcloud(word_freq$word,word_freq$count,min.freq=25)
library("dplyr", lib.loc="~/R/win-library/3.4")
library("janeaustenr", lib.loc="~/R/win-library/3.4")
library("gutenbergr", lib.loc="~/R/win-library/3.4")
library("stringr", lib.loc="~/R/win-library/3.4")
library("tidytext", lib.loc="~/R/win-library/3.4")
library("tm", lib.loc="~/R/win-library/3.4")
library("wordcloud", lib.loc="~/R/win-library/3.4")
words_df<-sns%>%
unnest_tokens(word,text)
words_df<-words_df%>%
filter(!(word %in% stop_words$word))
word_freq<-words_df%>%
group_by(word)%>%
summarize(count=n())
wordcloud(word_freq$word,word_freq$count,min.freq=25)
words_df<-sns%>%
unnest_tokens(word,text)
# Chunk 1
library(janeaustenr)
sns<-austen_books()
# Chunk 2
library(dplyr)
sns<-sns%>%
filter(book == 'Sense & Sensibility')
head(sns)
# Chunk 3
library(stringr)
sns<-sns%>%
filter(!str_detect(sns$text,'^CHAPTER'))
# Chunk 4
sns<-sns[12:12574,]
# Chunk 5
library(tidytext)
words_df<-sns%>%
unnest_tokens(word,text)
words_df
# Chunk 6
words_df<-words_df%>%
filter(!(word %in% stop_words$word))
words_df
# Chunk 7
word_freq<-words_df%>%
group_by(word)%>%
summarize(count=n())
word_freq
# Chunk 8
library(wordcloud)
library(tm)
wordcloud(word_freq$word,word_freq$count,min.freq=25)
library("dplyr", lib.loc="~/R/win-library/3.4")
library("gutenbergr", lib.loc="~/R/win-library/3.4")
library("ggplot2", lib.loc="~/R/win-library/3.4")
#This is how you search for the book #!!!!!!!
gutenberg_works(str_detect(title,'Frankenstein'))
library("stringr", lib.loc="~/R/win-library/3.4")
#This is how you search for the book #!!!!!!!
gutenberg_works(str_detect(title,'Frankenstein'))
#head(frankenstein) in the console shows you the dataframe is there
frankenstein<-gutenberg_download(84)
frankenstein(head)
head(frankenstein)
frankenstein_words<-unnest_tokens(frankenstein,word,text)
#Remove that column from the dataframe
frankenstein$gutenberg_id<-NULL
frankenstein_words<-unnest_tokens(frankenstein,word,text)
library("tidytext", lib.loc="~/R/win-library/3.4")
frankenstein_words<-unnest_tokens(frankenstein,word,text)
frankenstein(head()
frankenstein(head)
head(frankenstein)
afinn<-get_sentiments('afinn')
View(afinn)
#dim(frankenstein_words) in the console tells you how many words there are!
frankenstein_words$word_number<-1:5485
#dim(frankenstein_words) in the console tells you how many words there are!
frankenstein_words$word_number<-1:5485
gutenberg_works(str_detect(title,'Frankenstein'))
#head(frankenstein) in the console shows you the dataframe is there
frankenstein<-gutenberg_download(84)
#Remove that column from the dataframe
frankenstein$gutenberg_id<-NULL
#Remove that column from the dataframe
frankenstein$gutenberg_id<-NULL
afinn<-get_sentiments('afinn')
#dim(frankenstein_words) in the console tells you how many words there are!
frankenstein_words$word_number<-1:5485
#Add the afinn scores that correlate to the words in the dataframe
frankenstein_words<-inner_join(frankenstein_words,afinn)
head(frankenstein_words)
#Add new column to the dataframe with accumulated sums for affin word scores
frankenstein_words$accumulated_sentiment<-cumsum(frankenstein_words$score)
head(frankenstein_words)
#This is how you search for the book #!!!!!!!
#Use packages dplyr, gutenbergr, ggplot2, stringr, tidytext
gutenberg_works(str_detect(title,'Frankenstein'))
#head(frankenstein) in the console shows you the dataframe is there
frankenstein<-gutenberg_download(84)
#Remove that column from the dataframe
frankenstein$gutenberg_id<-NULL
afinn<-get_sentiments('afinn')
#dim(frankenstein_words) in the console tells you how many words there are!
frankenstein_words$word_number<-1:5485
#Add the afinn scores that correlate to the words in the dataframe
frankenstein_words<-inner_join(frankenstein_words,afinn)
head(frankenstein)
#Add the afinn scores that correlate to the words in the dataframe
frankenstein_words<-inner_join(frankenstein_words,afinn)
head(frankenstein)
#This is how you search for the book #!!!!!!!
#Use packages dplyr, gutenbergr, ggplot2, stringr, tidytext
gutenberg_works(str_detect(title,'Frankenstein'))
#head(frankenstein) in the console shows you the dataframe is there
frankenstein<-gutenberg_download(84)
#Remove that column from the dataframe
frankenstein$gutenberg_id<-NULL
afinn<-get_sentiments('afinn')
#dim(frankenstein_words) in the console tells you how many words there are!
frankenstein_words$word_number<-1:5485
#Add the afinn scores that correlate to the words in the dataframe
frankenstein_words<-inner_join(frankenstein_words,afinn)
head(frankenstein)
#This is how you search for the book #!!!!!!!
#Use packages dplyr, gutenbergr, ggplot2, stringr, tidytext
gutenberg_works(str_detect(title,'Frankenstein'))
#head(frankenstein) in the console shows you the dataframe is there
frankenstein<-gutenberg_download(84)
#Remove that column from the dataframe
frankenstein$gutenberg_id<-NULL
afinn<-get_sentiments('afinn')
#dim(frankenstein_words) in the console tells you how many words there are!
frankenstein_words$word_number<-1:5485
head(frankenstein)
#Add the afinn scores that correlate to the words in the dataframe
frankenstein_words<-inner_join(frankenstein_words,afinn)
head(frankenstein)
head(frankenstein)
head(frankenstein_words)
#This is how you search for the book #!!!!!!!
#Use packages dplyr, gutenbergr, ggplot2, stringr, tidytext
gutenberg_works(str_detect(title,'Frankenstein'))
#head(frankenstein) in the console shows you the dataframe is there
frankenstein<-gutenberg_download(84)
#Remove that column from the dataframe
frankenstein$gutenberg_id<-NULL
frankenstein_words<-unnest_tokens(frankenstein,word,text)
head(frankenstein_words)
afinn<-get_sentiments('afinn')
#dim(frankenstein_words) in the console tells you how many words there are!
frankenstein_words$word_number<-1:5485
#Add the afinn scores that correlate to the words in the dataframe
frankenstein_words<-inner_join(frankenstein_words,afinn)
head(frankenstein_words)
frankenstein_words%>%
mutate(acc_sum = cumsum(score))
head(frankenstein_words)
#This is how you search for the book #!!!!!!!
#Use packages dplyr, gutenbergr, ggplot2, stringr, tidytext
gutenberg_works(str_detect(title,'Frankenstein'))
#head(frankenstein) in the console shows you the dataframe is there
frankenstein<-gutenberg_download(84)
#Remove that column from the dataframe
frankenstein$gutenberg_id<-NULL
frankenstein_words<-unnest_tokens(frankenstein,word,text)
afinn<-get_sentiments('afinn')
#dim(frankenstein_words) in the console tells you how many words there are!
frankenstein_words$word_number<-1:5485
#Add the afinn scores that correlate to the words in the dataframe
frankenstein_words<-inner_join(frankenstein_words,afinn)
frankenstein_words$accumulated_sentiment<-cumsum(frankenstein_words$score)
head(frankenstein_words)
#This is how you search for the book #!!!!!!!
#Use packages dplyr, gutenbergr, ggplot2, stringr, tidytext
gutenberg_works(str_detect(title,'Frankenstein'))
#head(frankenstein) in the console shows you the dataframe is there
frankenstein<-gutenberg_download(84)
#Remove that column from the dataframe
frankenstein$gutenberg_id<-NULL
afinn<-get_sentiments('afinn')
#dim(frankenstein_words) in the console tells you how many words there are!
frankenstein_words$word_number<-1:5485
#Add the afinn scores that correlate to the words in the dataframe
frankenstein_words<-inner_join(frankenstein_words,afinn)
frankenstein_words%>%
mutate(acc_sum = cumsum(score))%>%
head
frankenstein_words%>%
mutate(acc_sum = cumsum(score))
frankenstein_words$accumulated_sentiment<-cumsum(frankenstein_words$score)
#This is how you search for the book #!!!!!!!
#Use packages dplyr, gutenbergr, ggplot2, stringr, tidytext
gutenberg_works(str_detect(title,'Frankenstein'))
#head(frankenstein) in the console shows you the dataframe is there
frankenstein<-gutenberg_download(84)
#Remove that column from the dataframe
frankenstein$gutenberg_id<-NULL
frankenstein_words<-unnest_tokens(frankenstein,word,text)
afinn<-get_sentiments('afinn')
View(afinn)
view(afinn)
head(affin)
#dim(frankenstein_words) in the console tells you how many words there are!
frankenstein_words$word_number<-1:5485
#Add the afinn scores that correlate to the words in the dataframe
frankenstein_words<-inner_join(frankenstein_words,afinn)
#Add new column to the dataframe with accumulated sums for affin word scores
frankenstein_words$accumulated_sentiment<-cumsum(frankenstein_words$score)
ggplot()+
geom_line(data=frankenstein_words,aes(x=word_number,y=accumulated_sentiment))+
ggtitle('Accumulated Sentiment for Frankenstein')
ggplot()+
geom_line(data=frankenstein_words,aes(x=word_number,y=accumulated_sentiment))+
ggtitle('Accumulated Sentiment for Frankenstein')
#This is how you search for the book #!!!!!!!
#Use packages dplyr, gutenbergr, ggplot2, stringr, tidytext
gutenberg_works(str_detect(title,'Frankenstein'))
#head(frankenstein) in the console shows you the dataframe is there
frankenstein<-gutenberg_download(84)
#Remove that column from the dataframe
frankenstein$gutenberg_id<-NULL
frankenstein_words<-unnest_tokens(frankenstein,word,text)
afinn<-get_sentiments('afinn')
#dim(frankenstein_words) in the console tells you how many words there are!
frankenstein_words$word_number<-1:5485
#Add the afinn scores that correlate to the words in the dataframe
frankenstein_words<-inner_join(frankenstein_words,afinn)
#Add new column to the dataframe with accumulated sums for affin word scores
frankenstein_words$accumulated_sentiment<-cumsum(frankenstein_words$score)
ggplot()+
geom_line(data=frankenstein_words,aes(x=word_number,y=accumulated_sentiment))+
ggtitle('Accumulated Sentiment for Frankenstein')
gutenberg_works(str_detect(title,'Frankenstein'))
frankenstein<-gutenberg_download(84)
frankenstein_words<-unnest_tokens(frankenstein,word,text)
frankenstein_words$word_number<-1:75175
frankenstein_words$gutenberg_id<-NULL
afinn<-get_sentiments('afinn')
frankenstein_words<-inner_join(frankenstein_words,afinn)
frankenstein_words$acc_sent<-cumsum(frankenstein_words$score)
ggplot()+
geom_line(data=frankenstein_words,aes(x=word_number,y=acc_sent))
#This is how you search for the book #!!!!!!!
#Use packages dplyr, gutenbergr, ggplot2, stringr, tidytext
gutenberg_works(str_detect(title,'Frankenstein'))
#head(frankenstein) in the console shows you the dataframe is there
frankenstein<-gutenberg_download(84)
#Remove that column from the dataframe
frankenstein_words$gutenberg_id<-NULL
frankenstein_words<-unnest_tokens(frankenstein,word,text)
afinn<-get_sentiments('afinn')
#dim(frankenstein_words) in the console tells you how many words there are!
frankenstein_words$word_number<-1:75175
#Add the afinn scores that correlate to the words in the dataframe
frankenstein_words<-inner_join(frankenstein_words,afinn)
#Add new column to the dataframe with accumulated sums for affin word scores
frankenstein_words$acc_sent<-cumsum(frankenstein_words$score)
gplot()+
geom_line(data=frankenstein_words,aes(x=word_number,y=acc_sent))
ggtitle('Accumulated Sentiment for Frankenstein')
ggplot()+
geom_line(data=frankenstein_words,aes(x=word_number,y=acc_sent))
ggtitle('Accumulated Sentiment for Frankenstein')
setwd("C:/Users/Judy/Desktop/ExamPrac3")
